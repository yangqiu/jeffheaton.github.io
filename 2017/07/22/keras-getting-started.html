<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Overview of Keras/TensorFlow Basic Operations | Heaton Research</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="I in the process of updating my deep learning course and books to make use of Keras.  This posting contains some of the basic examples that I put together. This post is not meant to be an introduction">
<meta property="og:type" content="article">
<meta property="og:title" content="Overview of Keras&#x2F;TensorFlow Basic Operations">
<meta property="og:url" content="http://www.heatonresearch.com/2017/07/22/keras-getting-started.html">
<meta property="og:site_name" content="Heaton Research">
<meta property="og:description" content="I in the process of updating my deep learning course and books to make use of Keras.  This posting contains some of the basic examples that I put together. This post is not meant to be an introduction">
<meta property="og:image" content="http://www.heatonresearch.com/images/content/keras_mnist_7.png">
<meta property="og:updated_time" content="2017-07-22T18:59:36.982Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Overview of Keras&#x2F;TensorFlow Basic Operations">
<meta name="twitter:description" content="I in the process of updating my deep learning course and books to make use of Keras.  This posting contains some of the basic examples that I put together. This post is not meant to be an introduction">
<meta name="twitter:image" content="http://www.heatonresearch.com/images/content/keras_mnist_7.png">
<meta name="twitter:creator" content="@jeffheaton">
  
    <link rel="alternate" href="/atom.xml" title="Heaton Research" type="application/atom+xml">
  
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" integrity="sha384-XdYbMnZ/QjLh6iI4ogqCTaIjrFk87ip+ekIjefZch0Y+PvJ8CDYtEs1ipDmPorQ+" crossorigin="anonymous">

  
  

  

  <link rel="stylesheet" href="/css/styles.css">
  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-5393865-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics --><!-- hexo-inject:begin --><!-- hexo-inject:end -->


</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav class="navbar navbar-inverse">
  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#main-menu-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
        <a class="navbar-brand" href="/">Heaton Research</a>
      
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="main-menu-navbar">
      <ul class="nav navbar-nav">
        
          <li><a class=""
                 href="/about/">About</a></li>
        
          <li><a class=""
                 href="/jeff/">Blog</a></li>
        
          <li><a class=""
                 href="/contact.html">Contact</a></li>
        
          <li><a class=""
                 href="/encog/">Encog</a></li>
        
          <li><a class=""
                 href="/book/">Books</a></li>
        
          <li><a class=""
                 href="/aifh/">AIFH</a></li>
        
          <li><a class=""
                 href="/jeff_index/">Articles</a></li>
        
          <li><a class=""
                 href="/archives/">Archives</a></li>
        
      </ul>

      <!--
      <ul class="nav navbar-nav navbar-right">
        
          <li><a href="/atom.xml" title="RSS Feed"><i class="fa fa-rss"></i></a></li>
        
      </ul>
      -->
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

  <div class="container">
    <div class="blog-header">
  <h1 class="blog-title">Heaton Research</h1>
  
</div>

<div class="row">
    <div class="col-sm-8 blog-main">
      <article id="post-keras-getting-started" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 class="article-title" itemprop="name">
      Overview of Keras/TensorFlow Basic Operations
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2017/07/22/keras-getting-started.html" class="article-date"><time datetime="2017-07-22T18:00:00.000Z" itemprop="datePublished">2017-07-22</time></a>
</div>

    
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/ai/">ai</a>
  </div>


  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <p>I in the process of updating my deep learning <a href="https://sites.wustl.edu/jeffheaton/t81-558/" target="_blank" rel="external">course</a> and <a href="http://www.aifh.org" target="_blank" rel="external">books</a> to make use of <a href="https://keras.io/" target="_blank" rel="external">Keras</a>.  This posting contains some of the basic examples that I put together. This post is not meant to be an introduction to neural networks in general.  For such an introduction, refer to either my <a href="/book/">books</a> or <a href="http://www.heatonresearch.com/content/non-mathematical-introduction-using-neural-networks">this article</a>.</p>
<p>I will expand on these examples greatly for both the book and course.  The basic neural network operations that I needed were:</p>
<ul>
<li>Simple Regression</li>
<li>Regression Early Stopping</li>
<li>Simple Classification</li>
<li>Classification Early Stopping</li>
<li>Deep Neural Networks w/Dropout and Other Regularization</li>
<li>Convolutional Neural Networks</li>
<li>LSTM Neural Networks</li>
<li>Loading/Saving Neural Networks</li>
</ul>
<p>These are some of the most basic operations that I need to perform when working with a new neural network package.  This provides me with a sort of Rosetta Stone for a new neural network package.  Once I have these operations, I can more easily create additional examples that are more complex.</p>
<p>The first thing to check is what versions you have of the required packages:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> keras</div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> sklearn <span class="keyword">as</span> sk</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"></div><div class="line">print(<span class="string">"Tensor Flow Version: &#123;&#125;"</span>.format(tf.__version__))</div><div class="line">print(<span class="string">"Keras Version: &#123;&#125;"</span>.format(keras.__version__))</div><div class="line">print()</div><div class="line">print(<span class="string">"Python &#123;&#125;"</span>.format(sys.version))</div><div class="line">print(<span class="string">'Pandas &#123;&#125;'</span>.format(pd.__version__))</div><div class="line">print(<span class="string">'Scikit-Learn &#123;&#125;'</span>.format(sk.__version__))</div></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Tensor Flow Version: 1.0.0</div><div class="line">Keras Version: 2.0.6</div><div class="line"></div><div class="line">Python 3.5.2 |Continuum Analytics, Inc.| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)]</div><div class="line">Pandas 0.19.2</div><div class="line">Scikit-Learn 0.18.1</div></pre></td></tr></table></figure>
<p>The following functions are from my set of <a href="https://github.com/jeffheaton/t81_558_deep_learning/blob/master/jeffs_helpful.ipynb" target="_blank" rel="external">helpful functions</a> that I created for my class and use in many of my <a href="http://www.aifh.org" target="_blank" rel="external">books</a>:  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</div><div class="line"></div><div class="line"><span class="comment"># Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">encode_text_dummy</span><span class="params">(df, name)</span>:</span></div><div class="line">    dummies = pd.get_dummies(df[name])</div><div class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> dummies.columns:</div><div class="line">        dummy_name = <span class="string">"&#123;&#125;-&#123;&#125;"</span>.format(name, x)</div><div class="line">        df[dummy_name] = dummies[x]</div><div class="line">    df.drop(name, axis=<span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="comment"># Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">encode_text_index</span><span class="params">(df, name)</span>:</span></div><div class="line">    le = preprocessing.LabelEncoder()</div><div class="line">    df[name] = le.fit_transform(df[name])</div><div class="line">    <span class="keyword">return</span> le.classes_</div><div class="line"></div><div class="line"><span class="comment"># Convert all missing values in the specified column to the median</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">missing_median</span><span class="params">(df, name)</span>:</span></div><div class="line">    med = df[name].median()</div><div class="line">    df[name] = df[name].fillna(med)</div><div class="line"></div><div class="line"><span class="comment"># Convert a Pandas dataframe to the x,y inputs that TensorFlow needs</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_xy</span><span class="params">(df, target)</span>:</span></div><div class="line">    result = []</div><div class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> df.columns:</div><div class="line">        <span class="keyword">if</span> x != target:</div><div class="line">            result.append(x)</div><div class="line"></div><div class="line">    <span class="comment"># find out the type of the target column.  Is it really this hard? :(</span></div><div class="line">    target_type = df[target].dtypes</div><div class="line">    target_type = target_type[<span class="number">0</span>] <span class="keyword">if</span> hasattr(target_type, <span class="string">'__iter__'</span>) <span class="keyword">else</span> target_type</div><div class="line"></div><div class="line">    <span class="comment"># Encode to int for classification, float otherwise. TensorFlow likes 32 bits.</span></div><div class="line">    <span class="keyword">if</span> target_type <span class="keyword">in</span> (np.int64, np.int32):</div><div class="line">        <span class="comment"># Classification</span></div><div class="line">        dummies = pd.get_dummies(df[target])</div><div class="line">        <span class="keyword">return</span> df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="comment"># Regression</span></div><div class="line">        <span class="keyword">return</span> df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)</div><div class="line"></div></pre></td></tr></table></figure>
<h2 id="Simple-Regression"><a href="#Simple-Regression" class="headerlink" title="Simple Regression"></a>Simple Regression</h2><p>Regression is where a neural network accepts several values (predictors) and produces a prediction that is numeric.  In this simple example we attempt to predict the miles per gallon (MPG) of several cars based on characteristics of those cars.  Several parameters and used below and described here.</p>
<ul>
<li><a href="https://keras.io/losses/" target="_blank" rel="external">Losses Supported by Keras</a><ul>
<li>Typically use <strong>mean_squared_error</strong> for regression (the square root of mean square error is root mean square error(RMSE)).</li>
<li>and for classification use: <strong>binary_crossentropy</strong> for 2 classes, <strong>categorical_crossentropy</strong> for more than 2 classes.</li>
</ul>
</li>
<li><a href="https://keras.io/initializers/" target="_blank" rel="external">kernel_initializer supported by Keras</a> - Species how the weights of are randomized.</li>
<li><a href="https://keras.io/activations/" target="_blank" rel="external">activation</a> - Usually relu or softmax will be used.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense, Activation</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> io</div><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</div><div class="line"></div><div class="line">url=<span class="string">"https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/data/auto-mpg.csv"</span></div><div class="line">df=pd.read_csv(io.StringIO(requests.get(url).content.decode(<span class="string">'utf-8'</span>)),na_values=[<span class="string">'NA'</span>,<span class="string">'?'</span>])</div><div class="line"></div><div class="line">cars = df[<span class="string">'name'</span>]</div><div class="line">df.drop(<span class="string">'name'</span>,<span class="number">1</span>,inplace=<span class="keyword">True</span>)</div><div class="line">missing_median(df, <span class="string">'horsepower'</span>)</div><div class="line">x,y = to_xy(df,<span class="string">"mpg"</span>)</div><div class="line"></div><div class="line">model = Sequential()</div><div class="line">model.add(Dense(<span class="number">10</span>, input_dim=x.shape[<span class="number">1</span>], activation=<span class="string">'relu'</span>))</div><div class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">'normal'</span>))</div><div class="line">model.compile(loss=<span class="string">'mean_squared_error'</span>, optimizer=<span class="string">'adam'</span>)</div><div class="line"></div><div class="line">model.fit(x,y,verbose=<span class="number">2</span>,epochs=<span class="number">100</span>)</div></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">Epoch 1/100</div><div class="line">0s - loss: 2240.8034</div><div class="line">Epoch 2/100</div><div class="line">0s - loss: 1469.8520</div><div class="line">Epoch 3/100</div><div class="line">0s - loss: 1038.2052</div><div class="line">Epoch 4/100</div><div class="line">0s - loss: 820.4976</div><div class="line">Epoch 5/100</div><div class="line"></div><div class="line">...</div><div class="line"></div><div class="line">0s - loss: 560.3524</div><div class="line">Epoch 99/100</div><div class="line">0s - loss: 559.7951</div><div class="line">Epoch 100/100</div><div class="line">0s - loss: 559.2341</div><div class="line">&lt;keras.callbacks.History at 0x2263d8cc518&gt;</div></pre></td></tr></table></figure>
<p>Now that the neural network is trained, we will test how good it is and perform some sample predictions.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">pred = model.predict(x)</div><div class="line"></div><div class="line"><span class="comment"># Measure RMSE error.  RMSE is common for regression.</span></div><div class="line">score = np.sqrt(metrics.mean_squared_error(pred,y))</div><div class="line">print(<span class="string">"Final score (RMSE): &#123;&#125;"</span>.format(score))</div><div class="line"></div><div class="line"><span class="comment"># Sample predictions</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</div><div class="line">    print(<span class="string">"&#123;&#125;. Car name: &#123;&#125;, MPG: &#123;&#125;, predicted MPG: &#123;&#125;"</span>.format(i+<span class="number">1</span>,cars[i],y[i],pred[i]))</div></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">Final score (RMSE): 3.494112253189087</div><div class="line">1. Car name: chevrolet chevelle malibu, MPG: [ 18.], predicted MPG: [ 14.94231319]</div><div class="line">2. Car name: buick skylark 320, MPG: [ 15.], predicted MPG: [ 14.08107567]</div><div class="line">3. Car name: plymouth satellite, MPG: [ 18.], predicted MPG: [ 15.15124226]</div><div class="line">4. Car name: amc rebel sst, MPG: [ 16.], predicted MPG: [ 15.84413433]</div><div class="line">5. Car name: ford torino, MPG: [ 17.], predicted MPG: [ 15.11468124]</div><div class="line">6. Car name: ford galaxie 500, MPG: [ 15.], predicted MPG: [ 10.48310184]</div><div class="line">7. Car name: chevrolet impala, MPG: [ 14.], predicted MPG: [ 10.11642265]</div><div class="line">8. Car name: plymouth fury iii, MPG: [ 14.], predicted MPG: [ 10.33946323]</div><div class="line">9. Car name: pontiac catalina, MPG: [ 14.], predicted MPG: [ 10.317276]</div><div class="line">10. Car name: amc ambassador dpl, MPG: [ 15.], predicted MPG: [ 12.37194347]</div></pre></td></tr></table></figure>
<h2 id="Regression-Early-Stop"><a href="#Regression-Early-Stop" class="headerlink" title="Regression (Early Stop)"></a>Regression (Early Stop)</h2><p>Early stopping sets aside a part of the data to be used to validate the neural<br>network.  The neural network is trained with the training data and validated<br>with the validation data.  Once the error no longer improves on the validation<br>set, the training stops.  This prevents the neural network from <a href="https://en.wikipedia.org/wiki/Overfitting" target="_blank" rel="external">overfitting</a>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> io</div><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense, Activation</div><div class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> EarlyStopping</div><div class="line"></div><div class="line">url=<span class="string">"https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/data/auto-mpg.csv"</span></div><div class="line">df=pd.read_csv(io.StringIO(requests.get(url).content.decode(<span class="string">'utf-8'</span>)),na_values=[<span class="string">'NA'</span>,<span class="string">'?'</span>])</div><div class="line"></div><div class="line">cars = df[<span class="string">'name'</span>]</div><div class="line">df.drop(<span class="string">'name'</span>,<span class="number">1</span>,inplace=<span class="keyword">True</span>)</div><div class="line">missing_median(df, <span class="string">'horsepower'</span>)</div><div class="line">x,y = to_xy(df,<span class="string">"mpg"</span>)</div><div class="line"></div><div class="line"><span class="comment"># Split into train/test</span></div><div class="line">x_train, x_test, y_train, y_test = train_test_split(    </div><div class="line">    x, y, test_size=<span class="number">0.25</span>, random_state=<span class="number">45</span>)</div><div class="line"></div><div class="line">model = Sequential()</div><div class="line">model.add(Dense(<span class="number">10</span>, input_dim=x.shape[<span class="number">1</span>], kernel_initializer=<span class="string">'normal'</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">'normal'</span>))</div><div class="line">model.compile(loss=<span class="string">'mean_squared_error'</span>, optimizer=<span class="string">'adam'</span>)</div><div class="line"></div><div class="line">monitor = EarlyStopping(monitor=<span class="string">'val_loss'</span>, min_delta=<span class="number">1e-3</span>, patience=<span class="number">5</span>, verbose=<span class="number">1</span>, mode=<span class="string">'auto'</span>)</div><div class="line"></div><div class="line">model.fit(x,y,validation_data=(x_test,y_test),callbacks=[monitor],verbose=<span class="number">2</span>,epochs=<span class="number">1000</span>)</div></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">Train on 398 samples, validate on 100 samples</div><div class="line">Epoch 1/1000</div><div class="line">0s - loss: 374.7638 - val_loss: 179.2396</div><div class="line">Epoch 2/1000</div><div class="line">0s - loss: 199.9990 - val_loss: 169.4834</div><div class="line">Epoch 3/1000</div><div class="line">0s - loss: 197.9431 - val_loss: 153.8338</div><div class="line">Epoch 4/1000</div><div class="line">0s - loss: 187.7644 - val_loss: 152.2758</div><div class="line">Epoch 5/1000</div><div class="line">0s - loss: 185.5505 - val_loss: 149.9817</div><div class="line"></div><div class="line">...</div><div class="line"></div><div class="line">Epoch 179/1000</div><div class="line">0s - loss: 10.3191 - val_loss: 8.2763</div><div class="line">Epoch 180/1000</div><div class="line">0s - loss: 10.0629 - val_loss: 8.3435</div><div class="line">Epoch 181/1000</div><div class="line">0s - loss: 10.7124 - val_loss: 8.4712</div><div class="line">Epoch 182/1000</div><div class="line">0s - loss: 10.6406 - val_loss: 8.4272</div><div class="line">&lt;keras.callbacks.History at 0x222a8ecd1d0&gt;</div></pre></td></tr></table></figure>
<h2 id="Classification-Model-Early-Stop"><a href="#Classification-Model-Early-Stop" class="headerlink" title="Classification Model (Early Stop)"></a>Classification Model (Early Stop)</h2><p>Early stopping can also be used with classification.  Early stopping sets aside a part of the data to be used to validate the neural network.  The neural network is trained with the training data and validated with the validation data.  Once the error no longer improves on the validation set, the training stops.  This prevents the neural network from <a href="https://en.wikipedia.org/wiki/Overfitting" target="_blank" rel="external">overfitting</a>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> io</div><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense, Activation</div><div class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> EarlyStopping</div><div class="line"></div><div class="line">url=<span class="string">"https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/data/iris.csv"</span></div><div class="line">df=pd.read_csv(io.StringIO(requests.get(url).content.decode(<span class="string">'utf-8'</span>)),na_values=[<span class="string">'NA'</span>,<span class="string">'?'</span>])</div><div class="line"></div><div class="line">species = encode_text_index(df,<span class="string">"species"</span>)</div><div class="line">x,y = to_xy(df,<span class="string">"species"</span>)</div><div class="line"></div><div class="line"><span class="comment"># Split into train/test</span></div><div class="line">x_train, x_test, y_train, y_test = train_test_split(    </div><div class="line">    x, y, test_size=<span class="number">0.25</span>, random_state=<span class="number">45</span>)</div><div class="line"></div><div class="line">model = Sequential()</div><div class="line">model.add(Dense(<span class="number">10</span>, input_dim=x.shape[<span class="number">1</span>], kernel_initializer=<span class="string">'normal'</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">'normal'</span>))</div><div class="line">model.add(Dense(y.shape[<span class="number">1</span>],activation=<span class="string">'softmax'</span>))</div><div class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=<span class="string">'adam'</span>)</div><div class="line"></div><div class="line">monitor = EarlyStopping(monitor=<span class="string">'val_loss'</span>, min_delta=<span class="number">1e-3</span>, patience=<span class="number">5</span>, verbose=<span class="number">1</span>, mode=<span class="string">'auto'</span>)</div><div class="line"></div><div class="line">model.fit(x,y,validation_data=(x_test,y_test),callbacks=[monitor],verbose=<span class="number">2</span>,epochs=<span class="number">1000</span>)</div></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">Train on 150 samples, validate on 38 samples</div><div class="line">Epoch 1/1000</div><div class="line">0s - loss: 1.1095 - val_loss: 1.1143</div><div class="line">Epoch 2/1000</div><div class="line">0s - loss: 1.1065 - val_loss: 1.1096</div><div class="line">Epoch 3/1000</div><div class="line">0s - loss: 1.1041 - val_loss: 1.1057</div><div class="line">Epoch 4/1000</div><div class="line">0s - loss: 1.1020 - val_loss: 1.1038</div><div class="line">Epoch 5/1000</div><div class="line">0s - loss: 1.1011 - val_loss: 1.1017</div><div class="line"></div><div class="line">...</div><div class="line"></div><div class="line">Epoch 325/1000</div><div class="line">0s - loss: 0.1758 - val_loss: 0.1320</div><div class="line">Epoch 326/1000</div><div class="line">0s - loss: 0.1755 - val_loss: 0.1332</div><div class="line">Epoch 00325: early stopping</div><div class="line">&lt;keras.callbacks.History at 0x222a9242d68&gt;</div></pre></td></tr></table></figure>
<p>Show the predictions (raw, probability of each class.)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Print out the raw predictions. Because there are 3 species of iris, there are 3 columns.  The number in each column is</span></div><div class="line"><span class="comment"># the probability that the flower is that type of iris.</span></div><div class="line"></div><div class="line">np.set_printoptions(suppress=<span class="keyword">True</span>)</div><div class="line">pred = model.predict(x_test)</div><div class="line">print(pred[<span class="number">0</span>:<span class="number">10</span>])</div></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[[ 0.97540218  0.0245978   0.        ]</div><div class="line"> [ 0.94149685  0.05850318  0.        ]</div><div class="line"> [ 0.02133332  0.27963796  0.69902873]</div><div class="line"> [ 0.94382465  0.05617536  0.        ]</div><div class="line"> [ 0.95254719  0.04745276  0.        ]</div><div class="line"> [ 0.95966363  0.04033642  0.        ]</div><div class="line"> [ 0.94291645  0.05708356  0.        ]</div><div class="line"> [ 0.00293462  0.06093681  0.93612856]</div><div class="line"> [ 0.00873046  0.14257514  0.84869444]</div><div class="line"> [ 0.00293431  0.0609317   0.93613404]]</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># The to_xy function represented the input in the same way.  Each row has only 1.0 value because each row is only one type</span></div><div class="line"><span class="comment"># of iris.  This is the training data, we KNOW what type of iris it is.  This is called one-hot encoding.  Only one value</span></div><div class="line"><span class="comment"># is 1.0 (hot)</span></div><div class="line"></div><div class="line">print(y_test[<span class="number">0</span>:<span class="number">10</span>])</div></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[[ 1.  0.  0.]</div><div class="line"> [ 1.  0.  0.]</div><div class="line"> [ 0.  0.  1.]</div><div class="line"> [ 1.  0.  0.]</div><div class="line"> [ 1.  0.  0.]</div><div class="line"> [ 1.  0.  0.]</div><div class="line"> [ 1.  0.  0.]</div><div class="line"> [ 0.  0.  1.]</div><div class="line"> [ 0.  0.  1.]</div><div class="line"> [ 0.  0.  1.]]</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> log_loss</div><div class="line"></div><div class="line"><span class="comment"># Using the predictions (pred) and the known 1-hot encodings (y_test) we can compute the log-loss error.  </span></div><div class="line"><span class="comment"># The lower a log loss the better.  The probabilities (pred) from the previous section specify how sure the neural network</span></div><div class="line"><span class="comment"># is of its prediction.  Log loss error pubishes the neural network (with a lower score) for very confident, but wrong,</span></div><div class="line"><span class="comment"># classifications.</span></div><div class="line">print(log_loss(y_test,pred))</div></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">0.133210815783</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Usually the column (pred) with the highest prediction is considered to be the prediction of the neural network.  It is easy</span></div><div class="line"><span class="comment"># to convert the predictions to the expected iris species.  The argmax function finds the index of the maximum prediction</span></div><div class="line"><span class="comment"># for each row.</span></div><div class="line"></div><div class="line">predict_classes = np.argmax(pred,axis=<span class="number">1</span>)</div><div class="line">expected_classes = np.argmax(y_test,axis=<span class="number">1</span>)</div><div class="line"></div><div class="line">print(<span class="string">"Predictions: &#123;&#125;"</span>.format(predict_classes))</div><div class="line">print(<span class="string">"Expected: &#123;&#125;"</span>.format(expected_classes))</div></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">Predictions: [0 0 2 0 0 0 0 2 2 2 0 2 2 2 2 0 2 2 0 1 1 1 2 1 0 2 1 1 0 1 1 1 2 2 0 2 0</div><div class="line"> 0]</div><div class="line">Expected: [0 0 2 0 0 0 0 2 2 2 0 2 2 2 2 0 2 2 0 1 1 1 2 1 0 2 1 1 0 1 1 1 2 2 0 2 0</div><div class="line"> 0]</div><div class="line"></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Of course it is very easy to turn these indexes back into iris species.  We just use the species list that we created earlier.</span></div><div class="line"></div><div class="line">print(species[predict_classes[<span class="number">1</span>:<span class="number">10</span>]])</div></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">['Iris-setosa' 'Iris-virginica' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'</div><div class="line"> 'Iris-setosa' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica']</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</div><div class="line"></div><div class="line"><span class="comment"># Accuracy might be a more easily understood error metric.  It is essentially a test score.  For all of the iris predictions,</span></div><div class="line"><span class="comment"># what percent were correct?  The downside is it does not consider how confident the neural network was in each prediction.</span></div><div class="line"></div><div class="line">correct = accuracy_score(expected_classes,predict_classes)</div><div class="line">print(<span class="string">"Accuracy: &#123;&#125;"</span>.format(correct))</div></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Accuracy: 1.0</div></pre></td></tr></table></figure>
<h2 id="Deeper-Networks"><a href="#Deeper-Networks" class="headerlink" title="Deeper Networks"></a>Deeper Networks</h2><p>Keras makes it easy to add addition layers as shown here:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> io</div><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</div><div class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> EarlyStopping</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout</div><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> regularizers</div><div class="line"></div><div class="line">url=<span class="string">"https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/data/auto-mpg.csv"</span></div><div class="line">df=pd.read_csv(io.StringIO(requests.get(url).content.decode(<span class="string">'utf-8'</span>)),na_values=[<span class="string">'NA'</span>,<span class="string">'?'</span>])</div><div class="line"></div><div class="line">cars = df[<span class="string">'name'</span>]</div><div class="line">df.drop(<span class="string">'name'</span>,<span class="number">1</span>,inplace=<span class="keyword">True</span>)</div><div class="line">missing_median(df, <span class="string">'horsepower'</span>)</div><div class="line">x,y = to_xy(df,<span class="string">"mpg"</span>)</div><div class="line"></div><div class="line"><span class="comment"># Split into train/test</span></div><div class="line">x_train, x_test, y_train, y_test = train_test_split(    </div><div class="line">    x, y, test_size=<span class="number">0.25</span>, random_state=<span class="number">45</span>)</div><div class="line"></div><div class="line"></div><div class="line">model = Sequential()</div><div class="line">model.add(Dense(<span class="number">50</span>, input_dim=x.shape[<span class="number">1</span>], kernel_initializer=<span class="string">'normal'</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(Dropout(<span class="number">0.2</span>))</div><div class="line">model.add(Dense(<span class="number">25</span>, input_dim=x.shape[<span class="number">1</span>], kernel_initializer=<span class="string">'normal'</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(Dense(<span class="number">10</span>, input_dim=<span class="number">64</span>,</div><div class="line">                kernel_regularizer=regularizers.l2(<span class="number">0.01</span>),</div><div class="line">                activity_regularizer=regularizers.l1(<span class="number">0.01</span>),activation=<span class="string">'relu'</span>))</div><div class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">'normal'</span>))</div><div class="line">model.compile(loss=<span class="string">'mean_squared_error'</span>, optimizer=<span class="string">'adam'</span>)</div><div class="line"></div><div class="line">monitor = EarlyStopping(monitor=<span class="string">'val_loss'</span>, min_delta=<span class="number">1e-3</span>, patience=<span class="number">5</span>, verbose=<span class="number">1</span>, mode=<span class="string">'auto'</span>)</div><div class="line"></div><div class="line">model.fit(x,y,validation_data=(x_test,y_test),callbacks=[monitor],verbose=<span class="number">0</span>,epochs=<span class="number">1000</span>)</div><div class="line">pred = model.predict(x_test)</div><div class="line"></div><div class="line"><span class="comment"># Measure RMSE error.  RMSE is common for regression.</span></div><div class="line">score = np.sqrt(metrics.mean_squared_error(pred,y_test))</div><div class="line">print(<span class="string">"Final score (RMSE): &#123;&#125;"</span>.format(score))</div></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Epoch 00064: early stopping</div><div class="line">Final score (RMSE): 4.421816825866699</div></pre></td></tr></table></figure>
<h2 id="The-Classic-MNIST-Dataset"><a href="#The-Classic-MNIST-Dataset" class="headerlink" title="The Classic MNIST Dataset"></a>The Classic MNIST Dataset</h2><p>The next examples will use the <a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="external">MNIST digits dataset</a>.  The previous examples used CSV files to load training data.  Most neural network frameworks, such as Keras, have common training sets built in.  This makes it easy to run the example, but hard to abstract the example to your own data.  Your on data are not likely built into Keras.  However, the MNIST data is complex enough that it is beyond the scope of this article to discuss how to load it.  We will use the MNIST data build into Keras.  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</div><div class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</div><div class="line"></div><div class="line">print(<span class="string">"Shape of x_train: &#123;&#125;"</span>.format(x_train.shape))</div><div class="line">print(<span class="string">"Shape of y_train: &#123;&#125;"</span>.format(y_train.shape))</div><div class="line">print()</div><div class="line">print(<span class="string">"Shape of x_test: &#123;&#125;"</span>.format(x_test.shape))</div><div class="line">print(<span class="string">"Shape of y_test: &#123;&#125;"</span>.format(y_test.shape))</div></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Shape of x_train: (60000, 28, 28)</div><div class="line">Shape of y_train: (60000,)</div><div class="line"></div><div class="line">Shape of x_test: (10000, 28, 28)</div><div class="line">Shape of y_test: (10000,)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Display as image</span></div><div class="line">%matplotlib inline</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">digit = <span class="number">101</span> <span class="comment"># Change to choose new digit</span></div><div class="line"></div><div class="line">a = x_train[digit]</div><div class="line">plt.imshow(a, cmap=<span class="string">'gray'</span>, interpolation=<span class="string">'nearest'</span>)</div><div class="line">print(<span class="string">"Image (#&#123;&#125;): Which is digit '&#123;&#125;'"</span>.format(digit,y_train[digit]))</div></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Image (#101): Which is digit '7'</div></pre></td></tr></table></figure>
<p><img src="/images/content/keras_mnist_7.png" alt="png"></p>
<h2 id="Convolutional-Neural-Networks"><a href="#Convolutional-Neural-Networks" class="headerlink" title="Convolutional Neural Networks"></a>Convolutional Neural Networks</h2><p>Convolutional Neural Networks are specifically for images.  They have been applied to other cases; however, use beyond images is somewhat rarer than with images.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> keras</div><div class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout, Flatten</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D, MaxPooling2D</div><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</div><div class="line"></div><div class="line">batch_size = <span class="number">128</span></div><div class="line">num_classes = <span class="number">10</span></div><div class="line">epochs = <span class="number">12</span></div><div class="line"></div><div class="line"><span class="comment"># input image dimensions</span></div><div class="line">img_rows, img_cols = <span class="number">28</span>, <span class="number">28</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> K.image_data_format() == <span class="string">'channels_first'</span>:</div><div class="line">    x_train = x_train.reshape(x_train.shape[<span class="number">0</span>], <span class="number">1</span>, img_rows, img_cols)</div><div class="line">    x_test = x_test.reshape(x_test.shape[<span class="number">0</span>], <span class="number">1</span>, img_rows, img_cols)</div><div class="line">    input_shape = (<span class="number">1</span>, img_rows, img_cols)</div><div class="line"><span class="keyword">else</span>:</div><div class="line">    x_train = x_train.reshape(x_train.shape[<span class="number">0</span>], img_rows, img_cols, <span class="number">1</span>)</div><div class="line">    x_test = x_test.reshape(x_test.shape[<span class="number">0</span>], img_rows, img_cols, <span class="number">1</span>)</div><div class="line">    input_shape = (img_rows, img_cols, <span class="number">1</span>)</div><div class="line"></div><div class="line">x_train = x_train.astype(<span class="string">'float32'</span>)</div><div class="line">x_test = x_test.astype(<span class="string">'float32'</span>)</div><div class="line">x_train /= <span class="number">255</span></div><div class="line">x_test /= <span class="number">255</span></div><div class="line">print(<span class="string">'x_train shape:'</span>, x_train.shape)</div><div class="line">print(<span class="string">"Training samples: &#123;&#125;"</span>.format(x_train.shape[<span class="number">0</span>]))</div><div class="line">print(<span class="string">"Test samples: &#123;&#125;"</span>.format(x_test.shape[<span class="number">0</span>]))</div><div class="line"></div><div class="line"><span class="comment"># convert class vectors to binary class matrices</span></div><div class="line">y_train = keras.utils.to_categorical(y_train, num_classes)</div><div class="line">y_test = keras.utils.to_categorical(y_test, num_classes)</div><div class="line"></div><div class="line">model = Sequential()</div><div class="line">model.add(Conv2D(<span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</div><div class="line">                 activation=<span class="string">'relu'</span>,</div><div class="line">                 input_shape=input_shape))</div><div class="line">model.add(Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</div><div class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</div><div class="line">model.add(Dropout(<span class="number">0.25</span>))</div><div class="line">model.add(Flatten())</div><div class="line">model.add(Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(Dropout(<span class="number">0.5</span>))</div><div class="line">model.add(Dense(num_classes, activation=<span class="string">'softmax'</span>))</div><div class="line"></div><div class="line">model.compile(loss=keras.losses.categorical_crossentropy,</div><div class="line">              optimizer=keras.optimizers.Adadelta(),</div><div class="line">              metrics=[<span class="string">'accuracy'</span>])</div><div class="line"></div><div class="line">model.fit(x_train, y_train,</div><div class="line">          batch_size=batch_size,</div><div class="line">          epochs=epochs,</div><div class="line">          verbose=<span class="number">2</span>,</div><div class="line">          validation_data=(x_test, y_test))</div><div class="line">score = model.evaluate(x_test, y_test, verbose=<span class="number">0</span>)</div><div class="line">print(<span class="string">'Test loss: &#123;&#125;'</span>.format(score[<span class="number">0</span>]))</div><div class="line">print(<span class="string">'Test accuracy: &#123;&#125;'</span>.format(score[<span class="number">1</span>]))</div></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">x_train shape: (60000, 28, 28, 1)</div><div class="line">Training samples: 60000</div><div class="line">Test samples: 10000</div><div class="line">Train on 60000 samples, validate on 10000 samples</div><div class="line">Epoch 1/12</div><div class="line">271s - loss: 0.3435 - acc: 0.8950 - val_loss: 0.0817 - val_acc: 0.9755</div><div class="line">Epoch 2/12</div><div class="line">269s - loss: 0.1171 - acc: 0.9660 - val_loss: 0.0581 - val_acc: 0.9813</div><div class="line">Epoch 3/12</div><div class="line">458s - loss: 0.0885 - acc: 0.9742 - val_loss: 0.0453 - val_acc: 0.9859</div><div class="line">Epoch 4/12</div><div class="line">554s - loss: 0.0743 - acc: 0.9778 - val_loss: 0.0382 - val_acc: 0.9867</div><div class="line">Epoch 5/12</div><div class="line">261s - loss: 0.0642 - acc: 0.9810 - val_loss: 0.0346 - val_acc: 0.9887</div><div class="line">Epoch 6/12</div><div class="line">321s - loss: 0.0594 - acc: 0.9826 - val_loss: 0.0337 - val_acc: 0.9888</div><div class="line">Epoch 7/12</div><div class="line">309s - loss: 0.0515 - acc: 0.9846 - val_loss: 0.0335 - val_acc: 0.9890</div><div class="line">Epoch 8/12</div><div class="line">317s - loss: 0.0477 - acc: 0.9857 - val_loss: 0.0337 - val_acc: 0.9890</div><div class="line">Epoch 9/12</div><div class="line">308s - loss: 0.0448 - acc: 0.9870 - val_loss: 0.0330 - val_acc: 0.9889</div><div class="line">Epoch 10/12</div><div class="line">322s - loss: 0.0416 - acc: 0.9873 - val_loss: 0.0307 - val_acc: 0.9901</div><div class="line">Epoch 11/12</div><div class="line">326s - loss: 0.0394 - acc: 0.9879 - val_loss: 0.0300 - val_acc: 0.9899</div><div class="line">Epoch 12/12</div><div class="line">313s - loss: 0.0367 - acc: 0.9887 - val_loss: 0.0313 - val_acc: 0.9902</div><div class="line">Test loss: 0.03131893762472173</div><div class="line">Test accuracy: 0.9902</div></pre></td></tr></table></figure>
<h2 id="Long-Short-Term-Memory-LSTM"><a href="#Long-Short-Term-Memory-LSTM" class="headerlink" title="Long Short Term Memory (LSTM)"></a>Long Short Term Memory (LSTM)</h2><p>Long Short Term Memory is typically used for either time series or natural language processing (which can be thought of as a special case of natural language processing).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> sequence</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Embedding</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM</div><div class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> imdb</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">max_features = <span class="number">4</span> <span class="comment"># 0,1,2,3 (total of 4)</span></div><div class="line">x = [</div><div class="line">    [[<span class="number">0</span>],[<span class="number">1</span>],[<span class="number">1</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>]],</div><div class="line">    [[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">2</span>],[<span class="number">2</span>],[<span class="number">0</span>]],</div><div class="line">    [[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">3</span>],[<span class="number">3</span>]],</div><div class="line">    [[<span class="number">0</span>],[<span class="number">2</span>],[<span class="number">2</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>]],</div><div class="line">    [[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">3</span>],[<span class="number">3</span>],[<span class="number">0</span>],[<span class="number">0</span>]],</div><div class="line">    [[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">1</span>],[<span class="number">1</span>]]</div><div class="line">]</div><div class="line">x = np.array(x,dtype=np.float32)</div><div class="line">y = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>],dtype=np.int32)</div><div class="line"></div><div class="line"><span class="comment"># Convert y2 to dummy variables</span></div><div class="line">y2 = np.zeros((y.shape[<span class="number">0</span>], max_features),dtype=np.float32)</div><div class="line">y2[np.arange(y.shape[<span class="number">0</span>]), y] = <span class="number">1.0</span></div><div class="line">print(y2)</div><div class="line"></div><div class="line">print(<span class="string">'Build model...'</span>)</div><div class="line">model = Sequential()</div><div class="line">model.add(LSTM(<span class="number">128</span>, dropout=<span class="number">0.2</span>, recurrent_dropout=<span class="number">0.2</span>, input_dim=<span class="number">1</span>))</div><div class="line">model.add(Dense(<span class="number">4</span>, activation=<span class="string">'sigmoid'</span>))</div><div class="line"></div><div class="line"><span class="comment"># try using different optimizers and different optimizer configs</span></div><div class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>,</div><div class="line">              optimizer=<span class="string">'adam'</span>,</div><div class="line">              metrics=[<span class="string">'accuracy'</span>])</div><div class="line"></div><div class="line">print(<span class="string">'Train...'</span>)</div><div class="line">model.fit(x,y2,epochs=<span class="number">200</span>)</div><div class="line">pred = model.predict(x)</div><div class="line">predict_classes = np.argmax(pred,axis=<span class="number">1</span>)</div><div class="line">print(<span class="string">"Predicted classes: &#123;&#125;"</span>,predict_classes)</div><div class="line">print(<span class="string">"Expected classes: &#123;&#125;"</span>,predict_classes)</div></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">[[ 0.  1.  0.  0.]</div><div class="line"> [ 0.  0.  1.  0.]</div><div class="line"> [ 0.  0.  0.  1.]</div><div class="line"> [ 0.  0.  1.  0.]</div><div class="line"> [ 0.  0.  0.  1.]</div><div class="line"> [ 0.  1.  0.  0.]]</div><div class="line">Build model...</div><div class="line"></div><div class="line"></div><div class="line">c:\users\jeffh\anaconda3\envs\tf-latest\lib\site-packages\ipykernel\__main__.py:27: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.</div><div class="line">c:\users\jeffh\anaconda3\envs\tf-latest\lib\site-packages\ipykernel\__main__.py:27: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, input_shape=(None, 1), recurrent_dropout=0.2, dropout=0.2)`</div><div class="line"></div><div class="line"></div><div class="line">Train...</div><div class="line">Epoch 1/200</div><div class="line">6/6 [==============================] - 2s - loss: 0.7078 - acc: 0.5000</div><div class="line">Epoch 2/200</div><div class="line">6/6 [==============================] - 0s - loss: 0.7006 - acc: 0.5000</div><div class="line">Epoch 3/200</div><div class="line">6/6 [==============================] - 0s - loss: 0.6896 - acc: 0.6667</div><div class="line">Epoch 4/200</div><div class="line">6/6 [==============================] - 0s - loss: 0.6861 - acc: 0.6667</div><div class="line">Epoch 5/200</div><div class="line">6/6 [==============================] - 0s - loss: 0.6754 - acc: 0.7083</div><div class="line"></div><div class="line">...</div><div class="line"></div><div class="line">Epoch 198/200</div><div class="line">6/6 [==============================] - 0s - loss: 0.2266 - acc: 0.9167</div><div class="line">Epoch 199/200</div><div class="line">6/6 [==============================] - 0s - loss: 0.2907 - acc: 0.8750</div><div class="line">Epoch 200/200</div><div class="line">6/6 [==============================] - 0s - loss: 0.1996 - acc: 0.9167</div><div class="line">Predicted classes: &#123;&#125; [1 2 3 2 3 1]</div><div class="line">Expected classes: &#123;&#125; [1 2 3 2 3 1]</div></pre></td></tr></table></figure>
<h2 id="Load-Save-a-Neural-Network"><a href="#Load-Save-a-Neural-Network" class="headerlink" title="Load/Save a Neural Network"></a>Load/Save a Neural Network</h2><p>It is very important to be able to load and save neural networks.  This allows your neural network to be used each time without retraining.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> io</div><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense, Activation</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</div><div class="line"></div><div class="line">url=<span class="string">"https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/data/auto-mpg.csv"</span></div><div class="line">df=pd.read_csv(io.StringIO(requests.get(url).content.decode(<span class="string">'utf-8'</span>)),na_values=[<span class="string">'NA'</span>,<span class="string">'?'</span>])</div><div class="line"></div><div class="line">cars = df[<span class="string">'name'</span>]</div><div class="line">df.drop(<span class="string">'name'</span>,<span class="number">1</span>,inplace=<span class="keyword">True</span>)</div><div class="line">missing_median(df, <span class="string">'horsepower'</span>)</div><div class="line">x,y = to_xy(df,<span class="string">"mpg"</span>)</div><div class="line"></div><div class="line">model = Sequential()</div><div class="line">model.add(Dense(<span class="number">10</span>, input_dim=x.shape[<span class="number">1</span>], kernel_initializer=<span class="string">'normal'</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">'normal'</span>))</div><div class="line">model.compile(loss=<span class="string">'mean_squared_error'</span>, optimizer=<span class="string">'adam'</span>)</div><div class="line"></div><div class="line">model.fit(x,y,verbose=<span class="number">2</span>,epochs=<span class="number">100</span>)</div></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">Epoch 1/100</div><div class="line">0s - loss: 188.3123</div><div class="line">Epoch 2/100</div><div class="line">0s - loss: 180.3333</div><div class="line">Epoch 3/100</div><div class="line">0s - loss: 177.1118</div><div class="line">Epoch 4/100</div><div class="line">0s - loss: 173.3682</div><div class="line">Epoch 5/100</div><div class="line">0s - loss: 167.0144</div><div class="line"></div><div class="line">...</div><div class="line"></div><div class="line">Epoch 98/100</div><div class="line">0s - loss: 11.2297</div><div class="line">Epoch 99/100</div><div class="line">0s - loss: 11.0280</div><div class="line">Epoch 100/100</div><div class="line">0s - loss: 10.9314</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">pred = model.predict(x)</div><div class="line"></div><div class="line"><span class="comment"># Measure RMSE error.  RMSE is common for regression.</span></div><div class="line">score = np.sqrt(metrics.mean_squared_error(pred,y))</div><div class="line">print(<span class="string">"Before save score (RMSE): &#123;&#125;"</span>.format(score))</div><div class="line"></div><div class="line"><span class="comment"># save neural network structure to JSON (no weights)</span></div><div class="line">model_json = model.to_json()</div><div class="line"><span class="keyword">with</span> open(<span class="string">"network.json"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> json_file:</div><div class="line">    json_file.write(model_json)</div><div class="line"></div><div class="line"><span class="comment"># save neural network structure to YAML (no weights)</span></div><div class="line">model_yaml = model.to_yaml()</div><div class="line"><span class="keyword">with</span> open(<span class="string">"network.yaml"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> yaml_file:</div><div class="line">    yaml_file.write(model_yaml)</div><div class="line"></div><div class="line"><span class="comment"># save entire network to HDF5 (save everything, suggested)</span></div><div class="line">model.save(<span class="string">"network.h5"</span>)</div></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Before save score (RMSE): 3.276093006134033</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</div><div class="line"></div><div class="line">model2 = load_model(<span class="string">'network.h5'</span>)</div><div class="line"></div><div class="line"><span class="comment"># Measure RMSE error.  RMSE is common for regression.</span></div><div class="line">score = np.sqrt(metrics.mean_squared_error(pred,y))</div><div class="line">print(<span class="string">"After load score (RMSE): &#123;&#125;"</span>.format(score))</div></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">After load score (RMSE): 3.276093006134033</div></pre></td></tr></table></figure>

      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="http://www.heatonresearch.com/2017/07/22/keras-getting-started.html" data-id="cj5fonpxu001ggovk3788dgj8" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
        <a href="http://www.heatonresearch.com/2017/07/22/keras-getting-started.html#disqus_thread" class="article-comment-link">
          <i class="fa fa-comment"></i> Comments
        </a>
      
      

    </footer>
  </div>
  
    
<ul id="article-nav" class="nav nav-pills nav-justified">
  
  <li role="presentation">
    <a href="/2017/07/13/jeffheaton-toolset.html.html" id="article-nav-older" class="article-nav-link-wrap">
      <i class="fa fa-chevron-left pull-left"></i>
      <span class="article-nav-link-title">My Current Software Toolkit</span>
    </a>
  </li>
  
  
</ul>


  
</article>


<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>


    </div>
    <div class="col-sm-3 col-sm-offset-1 blog-sidebar">
      
  <div class="sidebar-module sidebar-module-inset">
  <h4>About</h4>
  <p>Jeff Heaton is a computer scientist, data scientist, and indie publisher. Heaton Research is the homepage for his projects and research.</p>

</div>


  
  <div class="sidebar-module">
    <h4>Categories</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/ai/">ai</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/aifh/">aifh</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/datascience/">datascience</a><span class="sidebar-module-list-count">5</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/encog/">encog</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/gpu/">gpu</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/kaggle/">kaggle</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/learning/">learning</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/phd/">phd</a><span class="sidebar-module-list-count">7</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/python/">python</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/r/">r</a><span class="sidebar-module-list-count">4</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/tensorflow/">tensorflow</a><span class="sidebar-module-list-count">2</span></li></ul>
  </div>



  


  

  
  <div class="sidebar-module">
    <h4>Archives</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/07/">July 2017</a><span class="sidebar-module-list-count">3</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/05/">May 2017</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/03/">March 2017</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/01/">January 2017</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2016/09/">September 2016</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2016/03/">March 2016</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2016/02/">February 2016</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2015/09/">September 2015</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2015/08/">August 2015</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2015/05/">May 2015</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2015/03/">March 2015</a><span class="sidebar-module-list-count">4</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2014/12/">December 2014</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2014/09/">September 2014</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2014/05/">May 2014</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2014/02/">February 2014</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2013/07/">July 2013</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2013/06/">June 2013</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2013/04/">April 2013</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2013/03/">March 2013</a><span class="sidebar-module-list-count">1</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Recents</h4>
    <ul class="sidebar-module-list">
      
        <li>
          <a href="/2017/07/22/keras-getting-started.html">Overview of Keras/TensorFlow Basic Operations</a>
        </li>
      
        <li>
          <a href="/2017/07/13/jeffheaton-toolset.html.html">My Current Software Toolkit</a>
        </li>
      
        <li>
          <a href="/2017/07/05/finished-nsu-phd.html">Distance Computer Science PhD at Nova Southeastern University</a>
        </li>
      
        <li>
          <a href="/2017/05/25/ijcnn_2017.html">Presented at International Joint Conference on Neural Networks (IJCNN 2017)</a>
        </li>
      
        <li>
          <a href="/2017/03/03/python-basic-wikipedia-parsing.html">Reading Wikipedia XML Dumps with Python</a>
        </li>
      
    </ul>
  </div>



    </div>
</div>

  </div>
  <footer class="blog-footer">
  <div class="container">
    <div id="footer-info" class="inner">
      &copy; 2017 by Heaton Research, Inc. - <a href="/legal/">Legal and Copyright Info</a><br>
Jeff Heaton is a computer scientist, data scientist, and indie publisher. Heaton Research is the homepage for his projects and research.
    </div>
  </div>
</footer>

  
<script>
  var disqus_shortname = 'heatonresearch';
  
  var disqus_url = 'http://www.heatonresearch.com/2017/07/22/keras-getting-started.html';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha384-8gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>








<script src="/js/script.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
